---
title: "Demonstration of Caret for Machine Learning"
author: "JAS"
date: ""
output:
  word_document: default
  pdf_document: default
  html_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```
## Overview of the Caret Package

The caret package (Classification And REgression Training) contains a number of functions to streamline the process for creating analytic pipelines for prediction. It calls to other libraries to run algorithms, but provides a seamless and uniform interface for working with different algorithms.

Primary functionalities of caret include:

* pre-processing
* data splitting
* feature selection
* model tuning using resampling
* variable importance estimation

***

Helpful resources using caret:

Max Kuhn's explainer of the caret package
https://topepo.github.io/caret/model-training-and-tuning.html

Kuhn M. Building predictive models in R using the caret package. Journal of Statistical Software 2008;28(5) doi: 10.18637/jss.v028.i05

Webinar, given by Max Kuhn, available on YouTube (~1 hour): https://www.youtube.com/watch?v=7Jbb2ItbTC4


***
Data Source: UCI Machine Learning Repository, HCV data Dataset

The dataset contains laboratory values of blood donors (control) and Hepatitis C patients with varying levels of liver damage. Created by Lichtinghagen, Klawonn and Hoffmann. Lichtinghagen R et al. J Hepatol 2013; 59: 236-42


Attribute Information:

All attributes except Category and Sex are numerical. The laboratory data are the attributes 5-14.
1) X (Patient ID/No.)
2) Category (diagnosis) (values: '0=Blood Donor', '0s=suspect Blood Donor', '1=Hepatitis', '2=Fibrosis', '3=Cirrhosis')
3) Age (in years)
4) Sex (f,m)
5) ALB
6) ALP
7) ALT
8) AST
9) BIL
10) CHE
11) CHOL
12) CREA
13) GGT
14) PROT

### Some useful functions for pre-processing outside of the train function

```{r preprocess}
library(tidyverse)
library(caret)
library(stats)

#Read in data on liver function study
set.seed(111)
hcvdat0 <- read.csv("hcvdat0.csv")


#Make outcome category a factor var
hcvdat0$Category<-as.factor(hcvdat0$Category)

#Collapse factor levels of outcome variable
hcvdat0$outcome.class<-fct_collapse(hcvdat0$Category, NED=c("0=Blood Donor","0s=suspect Blood Donor"), LiverDisease=c("1=Hepatitis", "2=Fibrosis", "3=Cirrhosis"))

#Drop category and ID variable and remove missings
hcvdat0$Category<-NULL
hcvdat0$X<-NULL
hcvdat0<-na.omit(hcvdat0)

#Finding correlated predictors
hcvdat.numeric<- hcvdat0 %>% dplyr::select(where(is.numeric))
correlations<-cor(hcvdat.numeric, use="complete.obs")
high.correlations<-findCorrelation(correlations, cutoff=0.4)

#Remove highly correlated features
new.data.low.corr<-hcvdat.numeric[,-high.correlations]


#Centering and Scaling
set.up.preprocess<-preProcess(hcvdat.numeric, method=c("center", "scale"))
#Output pre-processed values
transformed.vals<-predict(set.up.preprocess, hcvdat.numeric)

#Creating balanced partitions in the data
train.index<-createDataPartition(hcvdat0$outcome.class, p=0.7, list=FALSE)

hcvdat.train<-hcvdat0[train.index,]
hcvdat.test<-hcvdat0[-train.index,]


#Construct k-folds in your data
train.folds<-createFolds(hcvdat0$outcome.class, k=10, list=FALSE)

```

### Model Training and Tuning

Using the train function to implement your analytic pipeline


```{r models}

#See what caret can do!
names(getModelInfo())

modelLookup("rpart")
modelLookup("adaboost")

#Train Function: used for tuning of hyperparameters and choosing "optimal" model

#Use trainControl Function to set validation method and options (default is bootstrap)

#Perform 10-fold cross-validation
control.settings<-trainControl(method="cv", number=10)

#Perform repeated 10-fold cross-validation
control.settings.b<-trainControl(method="repeatedcv", number=10, repeats=10)

#Perform sampling to balance data
control.settings.c<-trainControl(method="repeatedcv", number=10, repeats=10, sampling="down")

#Train function can be used to implement different algorithms using method=

#Demonstration of LASSO Algorithm using glmnet

#modelLookup will specify hyperparameters

modelLookup("glmnet")

set.seed(123)

lasso <- train(
 outcome.class ~., data = hcvdat.train, method = "glmnet", preProc=c("center", "scale"),
  trControl = control.settings.c)

lasso$results

#Don't depend on defaults for hyperparameters. Add tuning grid for lambda and alpha (but set alpha to 1 for LASSO)
lambda<-10^seq(-3,1, length=100)
lambda.grid<-expand.grid(alpha=1, lambda=lambda)

#Incorporate tuneGrid into train function 
set.seed(123)
lasso.2 <- train(
 outcome.class ~., data = hcvdat.train, method = "glmnet",preProc=c("center", "scale"),
  trControl = control.settings.c, tuneGrid = lambda.grid)


#Use plot to visualize tuning
plot(lasso.2)

#summaryFunction will allow calculation of sensitivity and specificity, classProbs= TRUE will allow the calculation of predicted probabilities

control.settings.d<-trainControl(method="repeatedcv", number=10, repeats=5, sampling="down", classProbs = TRUE, summaryFunction = twoClassSummary)

#Incorporate tuneGrid into train function and change evaluation metric to area under ROC curve
set.seed(123)
lasso.3 <- train(
 outcome.class ~., data = hcvdat.train, method = "glmnet",preProc=c("center", "scale"),
  trControl = control.settings.d, tuneGrid = lambda.grid, metric="ROC")
  
lasso.3$bestTune

#The tolerance function could be used to find a less complex model based on (x-xbest)/xbestx 100, which is #the percent difference. For example, to select parameter values based on a 2% loss of performance:

whichTwoPct <- tolerance(lasso.3$results, metric = "ROC", 
                         tol = 2, maximize = TRUE) 

lasso.3$results[whichTwoPct,1:6]


```

### Model Evaluation

```{r}

test.outcome<-predict(lasso.3, hcvdat.test)

confusionMatrix(test.outcome, hcvdat.test$outcome, positive="LiverDisease")
```




```{r}

```



