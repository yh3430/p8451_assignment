---
title: "Demonstration of Unsupervised Methods"
author: "JAS"
date: 
output:
  html_document: default
  word_document: default
editor_options:
  chunk_output_type: console
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


# Demonstration of Unsupervised Methods 

We will be using two different datasets to demonstrate different unsupervised machine learning methods. 

* Breast Cancer Imaging data 
    + Data Citation: This breast cancer database was obtained from the University of Wisconsin Hospitals, Madison from Dr.William H. Wolberg. 

* Simulated data that we will use to represent clinical phenotypic data on COPD extracted from an EHR system. 
    + Data Citation: Ultsch, A.: Clustering with SOM: U*C, In Proc. Workshop on Self-Organizing Maps, Paris, France, (2005) , pp. 75-82
    

***

### Load Packages Needed for Both Demonstrations
Ensure that all packages are installed. Note that the package ggbiplot is not available in R. We are downloading it from the developer's github repository.You do not need to replicate the use of ggbiplot.

```{r load_packages}
#First need to load package devtools and Rtools if you want to load packages from github
#library(devtools)

#install_github("vqv/ggbiplot")
library(ggbiplot)

library(stats)
library(factoextra)
library(cluster)

```

### Demonstration of Principal Components Analysis
First, we will utilize breast cancer imaging data. In this demonstration, rather than trying to predict malignancy, we are interested in determining if we can uncover the underlying constructs of the image that are explained by the nine features. In other words, can we reduce the number of features from nine down to some smaller number but still capture the same information. To accomplish this, we will apply principal components analysis to the feature data within the breast cancer dataset.

***

### Step 1: Load and Prepare Dataset
Remember to replace the file path with the location where the breast cancer data are stored.

```{r prepdata}
bc.data<-read.csv("breast-cancer-wisconsin.data.txt", header=FALSE)

var.names<-c("id", "clump_thickness", "uniformity_csize", "uniformity_cshape", "marg_adhesion", "single_ecell_size", "bare_nuclei", "b_chromatin", "normal_nucleoli", "mitoses", "outcome")
colnames(bc.data)<-var.names
str(bc.data)

#Clean data of '?' as in previous demonstration
bc.data[bc.data=="?"]<-NA
bc.data$bare_nuclei<-as.numeric(bc.data$bare_nuclei)

#Restrict to malignant cases
bc.data<-bc.data[(which(bc.data$outcome==4)),]

#Strip off the outcome and id variable
bc.data.features<-(bc.data[,2:10])

```

### Step 2: Determine if scaling is necessary

```{r scale}
#Obtain and compare means and standard deviations across features. na.rm removes the missings
colMeans(bc.data.features, na.rm=TRUE)
apply(bc.data.features, 2, sd, na.rm=TRUE)

#some difference in means and mitoses is different than others. So decide to center and scale

```

### Step 3: Conduct the Principal Components Analysis
The function prcomp() will center and scale the variables and then identify the principal components

```{r pca}

bc.pca<-prcomp( ~., data=bc.data.features, center=TRUE, scale=TRUE, na.action=na.omit)

#Can compare sds used to scale with the sds above to ensure they are close.
bc.pca$scale

#Generates scree plot
fviz_eig(bc.pca)

#view results of pca. Note the first three components are needed to explain at least 75% of the variance
summary(bc.pca)

#Identify how features loaded on the different components
bc.pca$rotation

ggbiplot(bc.pca)

ggbiplot(bc.pca, choices=c(2,3))

```

***
### Demonstration of Clustering Analysis
In this demonstration, we will attempt to uncover phenotypic subtypes within clinical data of Chronic Obstructive Pulmonary Disease (COPD). COPD is defined as airflow limitation that is not fully reversible. This is a very broad definition, and it suspected that there are a number of distinct phenotypes within the broader term of COPD. Identifying these subtypes can allow researchers to conduct more targeted investigations of COPD, uncovering mechanisms and risk factors for the different subtypes. This demonstration is loosely based on the work performed by Cho et al. Respiratory Research 2010; 11:30. The data are not the same. Please note that for practical reasons, we are using a small dataset with only 3 variables and 212 patient records. But, this same procedure could be repeated with a larger number of variables and/or records.

For this demonstration, the three variables in our dataset are:
1. post-bronchodilator FEV1 percent predicted
2. percent bronchodilator responsiveness
3. airway wall thickness

***

### Step 1: Load data and prepare for analysis
```{r dataprep2}
copd.data<-read.delim("Hepta.lrn", header=FALSE)

copd.data<-copd.data[,2:4]

var.names<-c("pb_FEV1_pctpred", "pct_br_resp", "awt")
colnames(copd.data)<-var.names

copd.data.nomiss<-na.omit(copd.data)

#Check means and SDs to determine if scaling is necessary
colMeans(copd.data.nomiss, na.rm=TRUE)
apply(copd.data.nomiss, 2, sd, na.rm=TRUE)

#Is scaling necessary?

```


### Step 2: Conduct a clustering analysis using k-means clustering
We can use the kmeans function in order to identify clusters within the data, based on the three variables.
```{r}
set.seed(100)
clusters<-kmeans(copd.data.nomiss, 5, nstart=25)
str(clusters)
fviz_cluster(clusters, data=copd.data.nomiss)
#Show the mean value of features within each cluster
clusters$centers

#Conduct a gap_statistic analysis to determine optimal number of clusters
set.seed(100)
gap_stat<-clusGap(copd.data.nomiss, FUN=kmeans, nstart=25, K.max=9, B=10)
print(gap_stat, method="firstmax")

clusters.7<-kmeans(copd.data.nomiss, 7, nstart=25)

str(clusters.7)

fviz_cluster(clusters.7, data=copd.data.nomiss)
```

### Step 3: Conduct a hierarchical clustering analysis
Note there are different methods you can use to create your dissimilarity matrix. We are using complete linkage in this demonstration, which tends to produce more compact clusters. 
```{r}
# Create Dissimilarity matrix
diss.matrix <- dist(copd.data.nomiss, method = "euclidean")

# Hierarchical clustering using Complete Linkage
clusters.h<- hclust(diss.matrix, method = "complete" )

# Plot the obtained dendrogram
plot(clusters.h, cex = 0.6, hang = -1)

#create function to use within clusGap
hclusCut <- function(x, k) list(cluster = cutree(hclust(dist(x, method="euclidian"), method="average"), k=k))

gap_stat <- clusGap(copd.data.nomiss, FUN = hclusCut, K.max = 10, B = 50)
fviz_gap_stat(gap_stat)


#Use number of clusters from gap statistic to obtain cluster assignment for each observation
clusters.h.7<-cutree(clusters.h, k=7)
table(clusters.h.7)

#Alternatives for hierarchical clustering

clusters.hcut<-hcut(copd.data.nomiss, k=5, hc_func="hclust", hc_method="single", hc_metric="euclidian")

clusters.hcut$size
fviz_dend(clusters.hcut, rect=TRUE)
fviz_cluster(clusters.hcut)

gap_stat <- clusGap(copd.data.nomiss, FUN = hcut, hc_method="single", K.max = 10, B = 5)
fviz_gap_stat(gap_stat)

input.feature.vals<-cbind(copd.data.nomiss,cluster=clusters.hcut$cluster)

input.feature.vals %>%
  group_by(cluster) %>%
  summarise_all(mean)

#GENERAL SYNTAX
#input.feature.vals<-cbind(orig.data,cluster=cluster.object$cluster)

#input.feature.vals %>%
 # group_by(`cluster.object$cluster`) %>%
  #summarise_all(mean)

```


