---
title: "Demonstration Class 5: Regularized Regression, K-Nearest Neighbors and Naive Bayes"
author: "JAS"
date: ''
output:
  html_document: default
  word_document: default
editor_options:
  chunk_output_type: console
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Demonstration of Regularization Methods

This will be a demonstration of the three regularization methods discussed: ridge regression, Lasso (least absolute shrinkage and selection operator) and Elastic Net.

## Description of Data

The data we will be using are from the 2019 County Health Rankings. They provide data on a number of demographic, social, environmental and health characteristics on counties within the United States. *We will be using this dataset to try to identify the most important predictors of life expectancy on a county-level.* We have restricted the dataset to 67 features and an outcome of life expectancy in years. 

Original data upon which this exercise has been based can be found here: http://www.countyhealthrankings.org/explore-health-rankings/rankings-data-documentation

Variable names are not originally informative. You can look up all full variable name meanings here: http://www.countyhealthrankings.org/sites/default/files/2019%20Analytic%20Documentation_1.pdf


### Load needed libraries
```{r}
library(tidyverse) 
library(caret)
library(glmnet)
library(klaR)
```

### Step 1: Read in data, partition, and put features into separate object 

When using CreateDataPartition, note that for numeric y, the sample is split into groups sections based on percentiles and sampling is done within these subgroups. This helps training and testing to be similar. Default number of quantiles is 5.

We are partitioning the data in a 70/30 split.

```{r data_prep}
set.seed(100)

chr<-read.csv("C:\\Users\\js5406\\OneDrive - cumc.columbia.edu\\EPIC Course\\chr.csv")

#Strip off ID Variable
chr<-chr[,2:68]

#Add informative feature names
var.names<-c("pre_death", "poorhealth", "poorphyshealth_days", "poormenthealth_days", "low_bwt", "ad_smoking", "ad_obesity", "foodenv_index", "phys_inactivity", "exer_access", "excess_drink", "alc_drivdeaths", "sti", "teen_birth", "uninsured", "primcareproviders", "dentists", "menthealthproviders", "prevhosp", "mammo_screen", "flu_vacc", "hsgrad", "somecollege", "unemployed", "child_poverty", "income_ineq", "sing_parent", "social_assoc", "violent_crime", "injury_deaths", "pm_air", "water_viol", "housing_prob", "driving_alone", "long_commute", "life_exp", "age_adj_premortality", "freq_physdistress", "freq_mentdistress", "diabetes", "hiv", "food_insecure", "ltd_access_healthyfood", "mvcrash_deaths", "insuff_sleep", "uninsured_adults", "uninsured_child", "other_pcp", "medhhinc", "freelunch_child", "res_seg_bw", "res_seg_nw", "firearm_fatalities", "homeownership", "hous_cost_burden", "population", "bw18", "gte65", "nonhisp_afam", "AmerInd_AlasNative", "Asian", "OPacIslander", "Hisp", "nonhisp_white", "nonprof_english", "female", "rural")

colnames(chr)<-var.names


#tidyverse way to create data partition
#training.data<-chr$life_exp %>% createDataPartition(p=0.7, list=F)

train.indices<-createDataPartition(y=chr$life_exp,p=0.7,list=FALSE)
train.data<-chr[train.indices, ]
test.data<-chr[-train.indices, ]


```

### Step 2: Running the algorithms on the training data

I will demonstrate regularized regression using the caret package. Note, it is the glmnet package that we will call to within caret. This package allows us to run all three of the penalized models using the same format. The value of the alpha parameter dictates whether it is a ride regression, lasso or elastic net. A value of 0 is the ridge regression, the 1 is a lasso and any value in between 0 and 1 will provide an elastic net. 

By default, caret will vary both alpha and lambda to select the best values via cross-validation. Because the alpha is not set at 0 or 1, this can (and often does) result in an elastic net. But, you can set the alpha level at a fixed value in order to obtain ridge or lasso results.

tuneLength sets the number of combinations of different values of alpha and lambda to compare. For example, setting tunelength to 10 will result in 10 values of alpha and 10 values of lambda


```{r reg_algorithms}
set.seed(123)

en.model<- train(
  life_exp ~., data = train.data, method = "glmnet",
  trControl = trainControl("cv", number = 10), preProc=c("center", "scale"),
 tuneLength=10
  )
#Print the values of alpha and lambda that gave best prediction
en.model$bestTune

#Print all of the options examined
en.model$results

# Model coefficients
coef(en.model$finalModel, en.model$bestTune$lambda)

# Make predictions in test set

en.pred <- en.model %>% predict(test.data)

# Model prediction performance
postResample(en.pred,test.data$life_exp)
data.frame(
  RMSE = RMSE(en.pred, test.data$life_exp),
  Rsquare = R2(en.pred, test.data$life_exp)
)


```

The following code will allow you to fix the alpha (I have it set to 0 for a ridge) and run either a ridge or lasso analysis. It also creates a sequence of lambda values that you set yourself to use for tuning.

If the caret package will select the optimal alpha and lambda value, why might you still choose lasso or ridge over elastic net (or an automated process of choosing alpha as in caret)? 

Exercise: using the code below as a start, tune both a ridge and lasso model. Compare evaluation metrics in the test set to what you obtained above from the elastic net.

```{r reg_exercise}
#Create grid to search lambda
lambda<-10^seq(-3,3, length=100)

set.seed(100)

#Note replacing tuneLength with tuneGrid
model.4<-train(
  life_exp ~., data=train.data, method="glmnet", trControl=trainControl("cv", number=10), preProc=c("center", "scale"), tuneGrid=expand.grid(alpha=0, lambda=lambda)
)

```


## Demonstration of K Nearest Neighbors

Using the caret package to implement KNN.

***
Data Description: 

Data come from the UCI Machine Learning Repository. This is a dataset containing clinical information about individuals who are either blood donors (i.e. healthy controls) or have varying severity of liver disease.

Data Set Information:

The target attribute for classification is Category (blood donors vs. Hepatitis C (including its progress ('just' Hepatitis C, Fibrosis, Cirrhosis).


Attribute Information:

All attributes except Category and Sex are numerical. The laboratory data are the attributes 5-14.
1) X (Patient ID/No.)
2) Category (diagnosis) (values: '0=Blood Donor', '0s=suspect Blood Donor', '1=Hepatitis', '2=Fibrosis', '3=Cirrhosis')
3) Age (in years)
4) Sex (f,m)
5) ALB
6) ALP
7) ALT
8) AST
9) BIL
10) CHE
11) CHOL
12) CREA
13) GGT
14) PROT

***

### Cleaning and partitioning data

Because knn is distance-based, we are going to restrict to only numerical (continuous) features. We will drop ID and Sex assignment. We will also collapse the outcome classification into a binary (Liver Disease, No Evidence of Disease). We are also excluding individuals with missing data.

```{r dataprep2}
set.seed(111)
hcvdat0 <- read.csv("C:/Users/js5406/Downloads/hcvdat0.csv")

#Look at features
str(hcvdat0)

#drop ID and sex variables
hcvdat0$X<-NULL
hcvdat0$Sex<-NULL


#Make outcome category a factor var
hcvdat0$Category<-as.factor(hcvdat0$Category)

#Collapse factor levels of outcome variable
hcvdat0$outcome.class<-fct_collapse(hcvdat0$Category, NED=c("0=Blood Donor","0s=suspect Blood Donor"), LiverDisease=c("1=Hepatitis", "2=Fibrosis", "3=Cirrhosis"))

#Drop category 
hcvdat0$Category<-NULL

#Check distributions, missing data etc.
summary(hcvdat0)

#Omit those with missing data
hcvdata<-na.omit(hcvdat0)

#Split data 70/30
train.indices<-hcvdata$outcome.class %>% createDataPartition(p=0.7, list=F)

train.data<-hcvdata[train.indices, ]
test.data<-hcvdata[-train.indices, ]

```

### Train and assess performance of model

We will use 10-fold cross validation to compare 10 different values of k. We will also use under-sampling due to the imbalance of the data.

```{r trainknn}
set.seed(111)

#Set control options..using 10-fold cross-validation and using under-sampling due to unbalanced data
trnctrl<-trainControl(method="cv", number=10, sampling="down")

knn.model.1<-train(outcome.class~.  , data=train.data, method="knn", trControl=trnctrl, preProcess=c("center", "scale"), tuneLength=10)

#Identify optimal number of k
knn.model.1$bestTune

#See full set of results
knn.model.1$results

plot(knn.model.1$results$k, knn.model.1$results$Accuracy, type="l")

#REPEAT using over-sampling due to unbalanced data
set.seed(111)
trnctrl<-trainControl(method="cv", number=10, sampling="up")

knn.model.2<-train(outcome.class~.  , data=train.data, method="knn", trControl=trnctrl, preProcess=c("center", "scale"), tuneLength=10)

k.vec<-seq(1,5,1)

knn.model.3<-train(outcome.class~.  , data=train.data, method="knn", trControl=trnctrl, preProcess=c("center", "scale"), tuneGrid=expand.grid(k=k.vec))

#Identify optimal number of k
knn.model.3$bestTune

#See full set of results
knn.model.3$results

plot(knn.model.3$results$k, knn.model.3$results$Accuracy, type="l")

```

### Make predictions in test-set using better model

```{r testknn}

model.results.3<-predict(knn.model.3, newdata=test.data)
confusionMatrix(model.results.3, test.data$outcome.class, positive="LiverDisease")
```

## Demonstration of Naive Bayes

Demonstrating naive bayes within caret using small toy dataset based on reading. 


## Load Data

Remove missings, make sure features are factors. Then partition 70/30. 


```{r dataprep3, echo=FALSE}
set.seed(1)
nb_test <- read.csv("C:/Users/js5406/OneDrive - cumc.columbia.edu/ML_Epi/2021/nb_test.csv")

#Remove missings
nb.test<-na.omit(nb_test)

nb.test[sapply(nb.test,is.numeric)]<-lapply(nb.test[sapply(nb.test,is.numeric)],as.factor)


train.indices<-createDataPartition(y=nb.test$COD,p=0.7,list=FALSE)

train.data.int<-nb.test[train.indices,2:7]
test.data.int<-nb.test[-train.indices,2:7]

train.data<-train.data.int[,1:5]
train.cod<-train.data.int[,6]

test.data<-test.data.int[,1:5]
test.cod<-as.factor(test.data.int[,6])
```

### Training a model on the data, apply to test set and evaluation

```{r}

control.settings<-trainControl(method='cv', number=5)
nb.model<-train(train.data, train.cod, method='nb', trControl=control.settings)
nb.model$results

nb.pred<-predict(nb.model, test.data)
confusionMatrix(nb.pred,test.cod)
```
