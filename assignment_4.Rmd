---
title: "assignment_4"
author: "Yu He"
date: "2023-02-07"
output: html_document
---

```{r}
library(tidyverse)
library(caret)
library(stats)
library(mgcv)
library(factoextra)
library(cluster)
library(fpc)

```

# Part 1 Implementing a Simple Prediction Pipeline
# Question 1 & 2
Step 1, prepare and cleaning the data
```{r}
# import the data and some data cleaning
hw4 = read_csv("class4_p1.csv") %>% 
  janitor::clean_names() %>% 
  mutate(
    across(c("chronic1", "chronic3", "chronic4",
             "tobacco1", "alcohol1", "habits5", "habits7", "agegroup", 
             "dem3", "dem4", "dem8", "povertygroup"), as.factor)
  ) %>% 
  na.omit() %>% 
  distinct(x1, .keep_all=TRUE) %>% 
  select(-x1)

#Finding correlated predictors
hw4_numeric<- hw4 %>% 
  dplyr::select(where(is.numeric))

hw4_correlations<-cor(hw4_numeric, use="complete.obs")
high_correlations_4<-findCorrelation(hw4_correlations, cutoff=0.4)
# None of the variable is highly correlated wih others

#Centering and Scaling
colMeans(hw4_numeric, na.rm=TRUE)
apply(hw4_numeric, 2, sd, na.rm=TRUE)

#Scaling is needed
set_up_preprocess<-preProcess(hw4_numeric, method=c("center", "scale"))

#Output pre-processed values
transformed_vals<-predict(set_up_preprocess, hw4_numeric)

#Creating balanced partitions in the data
train_index<-createDataPartition(hw4$healthydays, p=0.7, list=FALSE)

hw4_train<-hw4[train_index,]
hw4_test<-hw4[-train_index,]

#Construct k-folds in your data
train_folds<-createFolds(hw4$healthydays, k=10, list=FALSE)
```

Step 2, Model fit and training
```{r}
#Perform sampling to balance data
control_settings<-trainControl(method="repeatedcv", number=10, repeats=10)

modelLookup("lm")

set.seed(123)

lm_model_1 <- train(
 healthydays ~., data = hw4_train, method = "lm", preProc=c("center", "scale"), trControl = control_settings)

summary(lm_model_1)

lm_model_2 <- train(
 healthydays ~ chronic1 + chronic3 + chronic4 + bmi + tobacco1 + alcohol1 + gpaq8totmin + gpaq11days, data = hw4_train, method = "lm", preProc=c("center", "scale"), trControl = control_settings)

summary(lm_model_2)
```


Step 3, Model evaluation
```{r}
# Make predictions on the test data using both models
predictions_1 <- predict(lm_model_1, newdata = hw4_test)
predictions_2 <- predict(lm_model_2, newdata = hw4_test)

# Evaluate the performance of both models using mean squared error (MSE)
mse_1 <- postResample(predictions_1, hw4_test$healthydays)
mse_2 <- postResample(predictions_2, hw4_test$healthydays)

mse_1
mse_2

# Based on the above RMSE value (RMSE from model 1 < RMSE from model 2), we think the linear model 1 is the preferred model
# The implementation of the linear regression model can be used by agencies like department of health and insurance companies. Based on the predicted days with good physical health by multiple factors, agencies can provide health promotion guidelines and interventions to promote population health. Insurance companies can adjust their policies based on the model.
```


# Part 2 Conducting an Unsupervised Analysis
# Question 3 & 4
Step 1 prepare the data
```{r}
# prepare and clean the data
usarrests = 
  USArrests %>% 
  na.omit()
  
#Check means and SDs to determine if scaling is necessary
colMeans(usarrests, na.rm=TRUE)
apply(usarrests, 2, sd, na.rm=TRUE)

# scale the dataset
usarrests_scaled <- scale(usarrests)
```

Step 2, Conduct a clustering analysis using hierarchcal analysis
```{r}
set.seed(123)

# Create Dissimilarity matrix
diss_matrix <- dist(usarrests_scaled, method = "euclidean")

# Hierarchical clustering using Complete Linkage
clusters_hw4 <- hclust(diss_matrix, method = "complete" )

# Plot the obtained dendrogram
plot(clusters_hw4, cex = 0.6, hang = -1)

# create function to use within clusGap
hclusCut <- function(x, k) list(cluster = cutree(hclust(dist(x, method="euclidian"), method="average"), k=k))

gap_stat <- clusGap(usarrests_scaled, FUN = hclusCut, K.max = 15, B = 50)
fviz_gap_stat(gap_stat)

# Use number of clusters (optimal number of cluster is 2) from gap statistic to obtain cluster assignment for each observation
clusters.h.7<-cutree(clusters_hw4, k=2)
table(clusters.h.7)


# Alternative method check using k-mean method

clusters<-kmeans(usarrests_scaled, 5, nstart=25)
str(clusters)
fviz_cluster(clusters, data=usarrests_scaled)

#Show the mean value of features within each cluster
clusters$centers

#Conduct a gap_statistic analysis to determine optimal number of clusters
set.seed(100)
gap_stat<-clusGap(usarrests_scaled, FUN=kmeans, nstart=20, K.max=9, B=10)
print(gap_stat, method="firstmax")

# based on gap statistic, the optimal number of cluster is 4
clusters.7<-kmeans(usarrests_scaled, 4, nstart=20)

str(clusters.7)

fviz_cluster(clusters.7, data=usarrests_scaled)

cluster_df = as.data.frame(cbind(usarrests, Cluster = as.factor(clusters.7$cluster)))

cluster_composition = 
cluster_df %>% 
  group_by(Cluster) %>% 
  summarise_all(funs(mean))
cluster_composition
```

# Question 5
```{r}
# For example, the researchers can use the newly identified clusters as an exposure and compare the socio-economic characteristics (such as median household income, education level, etc.) between the states in each cluster to see if there is a difference.

# One ethical consideration can be bias: The results should be evaluated for potential bias, such as selection bias or measurement bias, and appropriate steps should be taken to minimize or control for these biases. The bias can originated from the the data collection process or collection method of USArrests data. When we train our algorithm, we should be careful of the outliers, overfitting and underfitting.
```






